---
title: "lec 8 hand-on session"
author: "YW"
date: "10/25/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## K-means clustering
using two # is the header of the document, and here is the text after the bold text header
Use "Knit" instead of "Run", because it "knit" everything together

Our fist xample with **kmeans()** function; quoted within two * is bold format

Make things look nice
Now, insert R code: 

```{r}
#example in R code
plot(1:10, typ="l")

```
Now, back to kmeans; option+command+I will insert R quickly
```{r}
# Generate some example data for clustering
tmp <- c(rnorm(30,-3), rnorm(30,3))
x <- cbind(x=tmp, y=rev(tmp))
plot(x)
cl <- kmeans(x,centers = 2,nstart = 20)
cl["cluster"]
points(cl$centers, col = "green", pch = 20, cex = 2)
points(x, col = cl$cluster)
 
```
 Use the kmeans() function setting k to 2 and nstart=20
 Inspect/print the results
 Q. How many points are in each cluster?
```{r}
table(cl$cluster)
```
 
 Q. What ‘component’ of your result object details
 - cluster size?
 - cluster assignment/membership?
 - cluster center?
 Plot x colored by the kmeans cluster assignment and
 add cluster centers as blue points
 Q. Repeat for k=3, which has the lower tot.withinss? 
```{r}
# 2nd: 3 cluster centers
tmp <- c(rnorm(30,-3), rnorm(30,3))
x <- cbind(x=tmp, y=rev(tmp))
plot(x)
cl2 <- kmeans(x,centers = 3,nstart = 20)
points(cl$centers, col = "green", pch = 20, cex = 2)
points(x, col = cl$cluster)
 
cl$totss
cl2$totss
```
## Hierarchical clustering in R
do **hcluse()** 

```{r}
d <- dist(x)
hc <- hclust(d)
plot(hc)
```

```{r}
d <- dist(x)
hc <- hclust(d)
hc
plot(hc) #out = dendrogram; default: method="complete"
abline(h=8,col="red")
cutree(hc,k = 2)
cutree(hc,h = 6)
```
### 

```{r}
plot(x, col=cut_1, pch=20) #plot: two cuts
plot(x, col=cut_2, pch=20) #plot: two cuts
```
# Q. How does this compare to your known 'col' groups?
```{r}
table(cut_2,col) #number of wrongly assigned group
```
################ PCA: 
#data analysis for many dimensions
## Initialize a blank 100 row by 10 column matrix
mydata <- matrix(nrow=100, ncol=10)
## Lets label the rows gene1, gene2 etc. to gene100
rownames(mydata) <- paste("gene", 1:100, sep="")
## Lets label the first 5 columns wt1, wt2, wt3, wt4 and wt5
## and the last 5 ko1, ko2 etc. to ko5 (for "knock-out")
colnames(mydata) <- c( paste("wt", 1:5, sep=""),
                       paste("ko", 1:5, sep="") )
## Fill in some fake read counts
for(i in 1:nrow(mydata)) {
  wt.values <- rpois(5, lambda=sample(x=10:1000, size=1))
  ko.values <- rpois(5, lambda=sample(x=10:1000, size=1))
  
  mydata[i,] <- c(wt.values, ko.values)
}
head(mydata)

##
## lets do PCA
pca <- prcomp(t(mydata), scale=TRUE) #T: transpose; always make scale
## See what is returned by the prcomp() function
attributes(pca)
# $names
#[1] "sdev" "rotation" "center" "scale" "x"
#
# $class
#[1] "prcomp"

#new PC plot
plot(pca$x[,1], pca$x[,2]) 
## Precent variance is often more informative to look at
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1) #standarize(?) proportion of score

pca.var.per #how much each pca counts
# [1] 91.0 2.8 1.9 1.3 0.8 0.7 0.6 0.5 0.3 0.0

#see which pca is the most important
barplot(pca.var.per, main="Scree Plot",
        xlab="Principal Component", ylab="Percent Variation")


## A vector of colors for wt and ko samples
colvec <- colnames(mydata)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"
plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
     xlab=paste0("PC1 (", pca.var.per[1], "%)"),
     ylab=paste0("PC2 (", pca.var.per[2], "%)")) 









